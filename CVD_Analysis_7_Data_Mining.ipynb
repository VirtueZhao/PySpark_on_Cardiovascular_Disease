{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cardio_data = pd.read_csv('cardio_train_new.csv')\n",
    "cardio_data = cardio_data.drop('id',axis=1)\n",
    "cardio_data.dropna(inplace=True)\n",
    "\n",
    "cardio_data = cardio_data.loc[cardio_data.ap_hi <= 220]\n",
    "cardio_data = cardio_data.loc[cardio_data.ap_hi >= 40]\n",
    "cardio_data = cardio_data.loc[cardio_data.ap_lo <= 220]\n",
    "cardio_data = cardio_data.loc[cardio_data.ap_lo >= 40]\n",
    "\n",
    "cardio_data.gender= cardio_data.gender.astype('str')\n",
    "cardio_data.height = cardio_data.height.astype('float64')\n",
    "cardio_data.ap_hi = cardio_data.ap_hi.astype('float64')\n",
    "cardio_data.ap_lo = cardio_data.ap_lo.astype('float64')\n",
    "cardio_data.cholesterol = cardio_data.cholesterol.astype('category')\n",
    "cardio_data.gluc = cardio_data.gluc.astype('category')\n",
    "cardio_data.smoke = cardio_data.smoke.astype('bool')\n",
    "cardio_data.alco = cardio_data.alco.astype('bool')\n",
    "cardio_data.active = cardio_data.active.astype('bool')\n",
    "cardio_data.cardio = cardio_data.cardio.astype('int64')\n",
    "\n",
    "cholesterol = cardio_data.cholesterol\n",
    "new_cholesterol = []\n",
    "for c in cholesterol:\n",
    "    if c == 1:\n",
    "        new_cholesterol.append(1)\n",
    "    else:\n",
    "        new_cholesterol.append(2)\n",
    "cardio_data['new_cholesterol'] = new_cholesterol\n",
    "cardio_data.new_cholesterol = cardio_data.new_cholesterol.astype('str')\n",
    "\n",
    "gluc = cardio_data.gluc\n",
    "new_gluc = []\n",
    "for g in gluc:\n",
    "    if g == 1:\n",
    "        new_gluc.append(1)\n",
    "    else:\n",
    "        new_gluc.append(2)\n",
    "cardio_data['new_gluc'] = new_gluc\n",
    "cardio_data.new_gluc = cardio_data.new_gluc.astype('str')\n",
    "\n",
    "cardio_data = cardio_data.drop('cholesterol', axis=1)\n",
    "cardio_data = cardio_data.drop('gluc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "spark = SparkSession.builder.appName('logistic_regression_adv').getOrCreate()\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_data_pyspark = spark.createDataFrame(cardio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "['age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'smoke', 'alco', 'active', 'cardio', 'new_cholesterol', 'new_gluc']\n",
      "root\n",
      " |-- age: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- height: double (nullable = true)\n",
      " |-- weight: double (nullable = true)\n",
      " |-- ap_hi: double (nullable = true)\n",
      " |-- ap_lo: double (nullable = true)\n",
      " |-- smoke: boolean (nullable = true)\n",
      " |-- alco: boolean (nullable = true)\n",
      " |-- active: boolean (nullable = true)\n",
      " |-- cardio: long (nullable = true)\n",
      " |-- new_cholesterol: string (nullable = true)\n",
      " |-- new_gluc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(cardio_data))\n",
    "print(type(cardio_data_pyspark))\n",
    "print(cardio_data_pyspark.columns)\n",
    "cardio_data_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_indexer = StringIndexer(inputCol='gender',outputCol='genderIndex')\n",
    "gender_encoder = OneHotEncoder(inputCol='genderIndex',outputCol='genderVec')\n",
    "cholesterol_index = StringIndexer(inputCol='new_cholesterol', outputCol='cholesterolIndex')\n",
    "cholesterol_encoder = OneHotEncoder(inputCol='cholesterolIndex', outputCol='cholesterolVec')\n",
    "gluc_indexer = StringIndexer(inputCol='new_gluc', outputCol='glucIndex')\n",
    "gluc_encoder = OneHotEncoder(inputCol='glucIndex', outputCol='glucVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['age',\n",
    "                                       'genderVec',\n",
    "                                       'height',\n",
    "                                       'weight',\n",
    "                                       'ap_hi',\n",
    "                                       'ap_lo',\n",
    "                                       'smoke',\n",
    "                                       'alco',\n",
    "                                       'active',\n",
    "                                       'cholesterolVec',\n",
    "                                       'glucVec'\n",
    "], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_data_pyspark = gender_indexer.fit(cardio_data_pyspark).transform(cardio_data_pyspark)\n",
    "cardio_data_pyspark = gender_encoder.transform(cardio_data_pyspark)\n",
    "\n",
    "cardio_data_pyspark = cholesterol_index.fit(cardio_data_pyspark).transform(cardio_data_pyspark)\n",
    "cardio_data_pyspark = cholesterol_encoder.transform(cardio_data_pyspark)\n",
    "\n",
    "cardio_data_pyspark = gluc_indexer.fit(cardio_data_pyspark).transform(cardio_data_pyspark)\n",
    "cardio_data_pyspark = gluc_encoder.transform(cardio_data_pyspark)\n",
    "\n",
    "cardio_data_pyspark = assembler.transform(cardio_data_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = cardio_data_pyspark.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- height: double (nullable = true)\n",
      " |-- weight: double (nullable = true)\n",
      " |-- ap_hi: double (nullable = true)\n",
      " |-- ap_lo: double (nullable = true)\n",
      " |-- smoke: boolean (nullable = true)\n",
      " |-- alco: boolean (nullable = true)\n",
      " |-- active: boolean (nullable = true)\n",
      " |-- cardio: long (nullable = true)\n",
      " |-- new_cholesterol: string (nullable = true)\n",
      " |-- new_gluc: string (nullable = true)\n",
      " |-- genderIndex: double (nullable = true)\n",
      " |-- genderVec: vector (nullable = true)\n",
      " |-- cholesterolIndex: double (nullable = true)\n",
      " |-- cholesterolVec: vector (nullable = true)\n",
      " |-- glucIndex: double (nullable = true)\n",
      " |-- glucVec: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cardio_data_pyspark.columns\n",
    "cardio_data_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = cardio_data_pyspark.randomSplit([0.8,.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='cardio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_model_1 = LogisticRegression(regParam=0, maxIter=100, labelCol='cardio')\n",
    "Logistic_model_2 = LogisticRegression(regParam=1, maxIter=100, labelCol='cardio')\n",
    "Logistic_model_3 = LogisticRegression(regParam=0, maxIter=200, labelCol='cardio')\n",
    "\n",
    "l1 = Logistic_model_1.fit(train_data)\n",
    "l2 = Logistic_model_2.fit(train_data)\n",
    "l3 = Logistic_model_3.fit(train_data)\n",
    "\n",
    "pred1 = l1.transform(test_data)\n",
    "pred2 = l2.transform(test_data)\n",
    "pred3 = l3.transform(test_data)\n",
    "\n",
    "AUC1 = evaluator.evaluate(pred1)\n",
    "print(\"Logistic Regression Model 1: \" + str(AUC1))\n",
    "AUC2 = evaluator.evaluate(pred2)\n",
    "print(\"Logistic Regression Model 2: \" + str(AUC2))\n",
    "AUC3 = evaluator.evaluate(pred3)\n",
    "print(\"Logistic Regression Model 3: \" + str(AUC3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model_1 = DecisionTreeClassifier(impurity='gini', labelCol='cardio')\n",
    "decision_tree_model_2 = DecisionTreeClassifier(impurity='entropy', labelCol='cardio')\n",
    "\n",
    "d1 = decision_tree_model_1.fit(train_data)\n",
    "d2 = decision_tree_model_2.fit(train_data)\n",
    "\n",
    "pred1 = d1.transform(test_data)\n",
    "pred2 = d2.transform(test_data)\n",
    "\n",
    "AUC1 = evaluator.evaluate(pred1)\n",
    "print(\"Decision Tree Model 1: \" + str(AUC1))\n",
    "AUC2 = evaluator.evaluate(pred2)\n",
    "print(\"Decision Tree Model 2: \" + str(AUC2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model_1 = RandomForestClassifier(numTrees=5, impurity='gini', labelCol='cardio')\n",
    "random_forest_model_2 = RandomForestClassifier(numTrees=10, impurity='gini', labelCol='cardio')\n",
    "random_forest_model_3 = RandomForestClassifier(numTrees=5, impurity='entropy', labelCol='cardio')\n",
    "\n",
    "clf1 = random_forest_model_1.fit(train_data)\n",
    "clf2 = random_forest_model_2.fit(train_data)\n",
    "clf3 = random_forest_model_3.fit(train_data)\n",
    "\n",
    "pred1 = clf1.transform(test_data)\n",
    "pred2 = clf2.transform(test_data)\n",
    "pred3 = clf3.transform(test_data)\n",
    "\n",
    "AUC1 = evaluator.evaluate(pred1)\n",
    "print(\"Random Forest Model 1: \" + str(AUC1))\n",
    "AUC2 = evaluator.evaluate(pred2)\n",
    "print(\"Random Forest Model 2: \" + str(AUC2))\n",
    "AUC3 = evaluator.evaluate(pred3)\n",
    "print(\"Random Forest Model 3: \" + str(AUC3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
